@article{10255703,
    abstract = {A new wave of artificial intelligence applications that offer extensive benefits to our daily lives has been led to by dramatic success in machine learning. The loss of explainability during this transition, however, means vulnerability to vicious data, poor model structure design, and suspicion of stakeholders and the general public--all with a range of legal implications. The study of explainable AI (XAI), which is an active research field that aims to make AI systems results more understandable to humans, has been called for by this dilemma. This is a field with great hopes for improving the trust and transparency of AI-based systems and is considered a necessary route for AI to move forward. A technological blueprint for building, deploying, and managing machine learning models, while meeting the requirements of transparent and trustworthy AI by adopting a variety of XAI methodologies, is provided by this guide. It defines the architectural framework and application guidelines for explainable AI, including: description and definition of XAI; the types of XAI methods and the application scenarios to which each type applies; and performance evaluation of XAI.},
    author = {},
    doi = {},
    issn = {},
    journal = {IEEE P2894/D8, August 2023},
    keywords = {IEEE Standards;Artificial intelligence;Software architecture;AI;architectural framework;artificial intelligence;explainable AI;explainable artificial intelligence;IEEE 2894\texttrademark ;machine learning;XAI},
    month = {Aug},
    number = {},
    pages = {1-51},
    title = {I{E}EE {D}raft {G}uide for an {A}rchitectural {F}ramework for {E}xplainable {A}rtificial {I}ntelligence},
    volume = {},
    year = {2023}
}

@inproceedings{9599411,
    abstract = {The development and adoption of artificial intelligence (AI) have brought numerous problems and potential threats, such as information cocoons, algorithmic collusion, algorithmic bias and privacy, issues. To combat these issues, governments all over the world, international organizations and giant tech companies all have taken actions and reached an agreement that AI should be trusted. However, there is no uniform definition on trusted AI. In the paper, we make a survey on related works on artificial intelligence principles and ethical guidelines. Then analyze the ethical foundations of trusted AI and give a definition on trusted AI. We propose specific requirements of trusted AI from a technical perspective and give explanations on these technique requirements. Finally, best practices are recommended to achieve trusted AI and promote the responsible use of AI.},
    author = {Zhang, Tao and Qin, Yi and Li, Qiang},
    booktitle = {2021 International Conference on Cyberworlds (CW)},
    doi = {10.1109/CW52790.2021.00058},
    issn = {2642-3596},
    keywords = {Ethics;Privacy;Government;Minimization;Robustness;Data governance;Safety;Artificial intelligence;trusted artificial intelligence;technique requirements;best practices},
    month = {Sep.},
    number = {},
    pages = {303-306},
    title = {{T}rusted {A}rtificial {I}ntelligence: {T}echnique {R}equirements and {B}est {P}ractices},
    volume = {},
    year = {2021}
}

@article{RASHIDI2025100687,
    abstract = {This review article builds upon the introductory piece in our 7-part series, delving deeper into the transformative potential of generative artificial intelligence (Gen AI) in pathology and medicine. The article explores the applications of Gen AI models in pathology and medicine, including the use of custom chatbots for diagnostic report generation, synthetic image synthesis for training new models, data set augmentation, hypothetical scenario generation for educational purposes, and the use of multimodal along with multiagent models. This article also provides an overview of the common categories within Gen AI models, discussing open-source and closed-source models, as well as specific examples of popular models such as GPT-4, Llama, Mistral, DALL-E, Stable Diffusion, and their associated frameworks (eg, transformers, generative adversarial networks, diffusion-based neural networks), along with their limitations and challenges, especially within the medical domain. We also review common libraries and tools that are currently deemed necessary to build and integrate such models. Finally, we look to the future, discussing the potential impact of Gen AI on health care, including benefits, challenges, and concerns related to privacy, bias, ethics, application programming interface costs, and security measures.},
    author = {Hooman H. Rashidi and Joshua Pantanowitz and Alireza Chamanzar and Brandon Fennell and Yanshan Wang and Rama R. Gullapalli and Ahmad Tafti and Mustafa Deebajah and Samer Albahra and Eric Glassy and Matthew G. Hanna and Liron Pantanowitz},
    doi = {https://doi.org/10.1016/j.modpat.2024.100687},
    issn = {0893-3952},
    journal = {Modern Pathology},
    keywords = {ChatGPT, diffusion, generative adversarial network, generative artificial intelligence, generative pretrained transformer, multiagent},
    number = {4},
    pages = {100687},
    title = {{G}enerative {A}rtificial {I}ntelligence in {P}athology and {M}edicine: {A} Deeper {D}ive},
    url = {https://www.sciencedirect.com/science/article/pii/S0893395224002679},
    volume = {38},
    year = {2025}
}

@article{MONZON2025,
    abstract = {Generative artificial intelligence (GenAI) presents novel approaches to enhance motivation, curriculum structure and development, and learning and retrieval processes for both learners and instructors. Though a focus for this emerging technology is academic misconduct, we sought to leverage GenAI in curriculum structure to facilitate educational outcomes. For instructors, GenAI offers new opportunities in course design and management while reducing time requirements to evaluate outcomes and personalizing learner feedback. These include innovative instructional designs such as flipped classrooms and gamification, enriching teaching methodologies with focused and interactive approaches, and team-based exercise development among others. For learners, GenAI offers unprecedented self-directed learning opportunities, improved cognitive engagement, and effective retrieval practices, leading to enhanced autonomy, motivation, and knowledge retention. Though empowering, this evolving landscape has integration challenges and ethical considerations, including accuracy, technological evolution, loss of learner’s voice, and socioeconomic disparities. Our experience demonstrates that the responsible application of GenAI’s in educational settings will revolutionize learning practices, making education more accessible and tailored, producing positive motivational outcomes for both learners and instructors. Thus, we argue that leveraging GenAI in educational settings will improve outcomes with implications extending from primary through higher and continuing education paradigms.},
    author = {Noahlana Monzon and Franklin Alan Hays},
    doi = {https://doi.org/10.2196/59210},
    issn = {2369-3762},
    journal = {JMIR Medical Education},
    keywords = {educational technology, retrieval practice, flipped classroom, cognitive engagement, personalized learning, generative artificial intelligence, higher education, university education, learners, instructors, curriculum structure, learning, technologies, innovation, academic misconduct, gamification, self-directed, socio-economic disparities, interactive approach, medical education, chatGPT, machine learning, AI, large language models},
    title = {{L}everaging {G}enerative {A}rtificial {I}ntelligence to {I}mprove {M}otivation and {R}etrieval in {H}igher {E}ducation {L}earners},
    url = {https://www.sciencedirect.com/science/article/pii/S2369376225000352},
    volume = {11},
    year = {2025}
}
