@article{10255703,
    abstract = {A new wave of artificial intelligence applications that offer extensive benefits to our daily lives has been led to by dramatic success in machine learning. The loss of explainability during this transition, however, means vulnerability to vicious data, poor model structure design, and suspicion of stakeholders and the general public--all with a range of legal implications. The study of explainable AI (XAI), which is an active research field that aims to make AI systems results more understandable to humans, has been called for by this dilemma. This is a field with great hopes for improving the trust and transparency of AI-based systems and is considered a necessary route for AI to move forward. A technological blueprint for building, deploying, and managing machine learning models, while meeting the requirements of transparent and trustworthy AI by adopting a variety of XAI methodologies, is provided by this guide. It defines the architectural framework and application guidelines for explainable AI, including: description and definition of XAI; the types of XAI methods and the application scenarios to which each type applies; and performance evaluation of XAI.},
    author = {},
    doi = {},
    issn = {},
    journal = {IEEE P2894/D8, August 2023},
    keywords = {IEEE Standards;Artificial intelligence;Software architecture;AI;architectural framework;artificial intelligence;explainable AI;explainable artificial intelligence;IEEE 2894\texttrademark ;machine learning;XAI},
    month = {Aug},
    number = {},
    pages = {1-51},
    title = {I{E}EE {D}raft {G}uide for an {A}rchitectural {F}ramework for {E}xplainable {A}rtificial {I}ntelligence},
    volume = {},
    year = {2023}
}
